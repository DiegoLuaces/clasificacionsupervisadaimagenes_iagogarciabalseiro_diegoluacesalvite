{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.applications import Xception, MobileNetV3Large\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.colab import drive\n",
    "\n",
    "# Montar Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Ruta y carga de datos\n",
    "ruta_base = '/content/drive/MyDrive/SCUBI DU'\n",
    "def is_valid_image(file_path):\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    return any(file_path.lower().endswith(ext) for ext in valid_extensions)\n",
    "\n",
    "clases_unicas = sorted([d for d in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, d))])\n",
    "class_to_label = {name: idx for idx, name in enumerate(clases_unicas)}\n",
    "\n",
    "imagenes_cargadas, etiquetas_cargadas = [], []\n",
    "for class_name in clases_unicas:\n",
    "    class_folder = os.path.join(ruta_base, class_name)\n",
    "    valid_images = [os.path.join(class_folder, f) for f in os.listdir(class_folder) if is_valid_image(f)]\n",
    "    for image_path in valid_images:\n",
    "        img = load_img(image_path, target_size=(224, 224))\n",
    "        imagenes_cargadas.append(np.array(img))\n",
    "        etiquetas_cargadas.append(class_to_label[class_name])\n",
    "\n",
    "X = np.array(imagenes_cargadas) / 255.0\n",
    "y_raw = np.array(etiquetas_cargadas)\n",
    "y = to_categorical(y_raw)\n",
    "\n",
    "# Parámetros óptimos fijos\n",
    "parametros_fijos = {\n",
    "    'batch_size': 6,\n",
    "    'activation': 'sigmoid',\n",
    "    'patience': 3,\n",
    "    'epochs': 10,\n",
    "    'learning_rate': 0.0001\n",
    "}\n",
    "\n",
    "# Configuraciones de capas\n",
    "layer_unit_configs = {\n",
    "    1: [[64], [128], [256]],\n",
    "    2: [[256, 128], [128, 64], [64, 32]],\n",
    "    3: [[256, 128, 64], [128, 64, 32], [64, 32, 16]]\n",
    "}\n",
    "\n",
    "# Valores de tolerancia\n",
    "modelos = {\n",
    "    'Xception': Xception,\n",
    "    'MobileNetV3Large': MobileNetV3Large\n",
    "}\n",
    "tolerancias = [0.005, 0.02]\n",
    "\n",
    "# Función para construir el modelo\n",
    "def build_model(base_model_fn, units_per_layer_list, activation='relu', learning_rate=0.001):\n",
    "    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    for units in units_per_layer_list:\n",
    "        model.add(layers.Dense(units, activation=activation))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(y.shape[1], activation='softmax'))\n",
    "    opt = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Validación cruzada 5-fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "resultados = []\n",
    "\n",
    "for nombre_modelo, modelo_base in modelos.items():\n",
    "    for tolerancia in tolerancias:\n",
    "        for num_layers, configs in layer_unit_configs.items():\n",
    "            for units_list in configs:\n",
    "                f1_macro_list, f1_weighted_list, precision_list, recall_list = [], [], [], []\n",
    "\n",
    "                for train_index, test_index in skf.split(X, y_raw):\n",
    "                    X_train, X_test = X[train_index], X[test_index]\n",
    "                    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                    model = build_model(\n",
    "                        base_model_fn=modelo_base,\n",
    "                        units_per_layer_list=units_list,\n",
    "                        activation=parametros_fijos['activation'],\n",
    "                        learning_rate=parametros_fijos['learning_rate']\n",
    "                    )\n",
    "                    es = callbacks.EarlyStopping(\n",
    "                        monitor='val_loss',\n",
    "                        patience=parametros_fijos['patience'],\n",
    "                        min_delta=tolerancia,\n",
    "                        restore_best_weights=True\n",
    "                    )\n",
    "                    model.fit(\n",
    "                        X_train, y_train,\n",
    "                        epochs=parametros_fijos['epochs'],\n",
    "                        batch_size=parametros_fijos['batch_size'],\n",
    "                        validation_split=0.2,\n",
    "                        callbacks=[es],\n",
    "                        verbose=0\n",
    "                    )\n",
    "\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    y_true = np.argmax(y_test, axis=1)\n",
    "                    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "                    f1_macro_list.append(f1_score(y_true, y_pred_class, average='macro'))\n",
    "                    f1_weighted_list.append(f1_score(y_true, y_pred_class, average='weighted'))\n",
    "                    precision_list.append(precision_score(y_true, y_pred_class, average='macro', zero_division=0))\n",
    "                    recall_list.append(recall_score(y_true, y_pred_class, average='macro', zero_division=0))\n",
    "\n",
    "                resultados.append({\n",
    "                    'modelo': nombre_modelo,\n",
    "                    'tolerancia': tolerancia,\n",
    "                    'num_layers': num_layers,\n",
    "                    'units_per_layer': str(units_list),\n",
    "                    'f1_macro': np.mean(f1_macro_list),\n",
    "                    'f1_weighted': np.mean(f1_weighted_list),\n",
    "                    'precision': np.mean(precision_list),\n",
    "                    'recall': np.mean(recall_list)\n",
    "                })\n",
    "\n",
    "# Guardar resultados\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados.to_excel(\"/content/resultados_comparacion_modelos_tolerancia_kfold.xlsx\", index=False)\n",
    "\n",
    "# Mejor configuración por modelo (mantiene todas las columnas, incluidas listas)\n",
    "top_idx = df_resultados.groupby('modelo')['f1_macro'].idxmax().dropna().astype(int)\n",
    "top_config = df_resultados.loc[top_idx].copy().reset_index(drop=True)\n",
    "top_config.to_excel(\"/content/top_combinaciones_f1_kfold.xlsx\", index=False)\n",
    "\n",
    "# Matrices de confusión para mejores combinaciones\n",
    "for _, row in top_config.iterrows():\n",
    "    if 'confusion_matrix' in row and isinstance(row['confusion_matrix'], list):\n",
    "        cm = np.array(row['confusion_matrix'])\n",
    "        modelo = row['modelo']\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=clases_unicas, yticklabels=clases_unicas, cbar=True, square=True, linewidths=0)\n",
    "        plt.title(f\"Matriz de Confusión Promedio (5-Fold): {modelo}\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/content/matriz_confusion_{modelo}_kfold.png\")\n",
    "        plt.show()\n",
    "\n",
    "# Gráficas comparativas\n",
    "sns.set(style=\"whitegrid\")\n",
    "for metric in ['f1_macro', 'f1_weighted', 'precision', 'recall']:\n",
    "    g = sns.catplot(\n",
    "        data=df_resultados,\n",
    "        kind='bar',\n",
    "        x='num_layers',\n",
    "        y=metric,\n",
    "        hue='units_per_layer',\n",
    "        col='modelo',\n",
    "        height=6,\n",
    "        aspect=1.2\n",
    "    )\n",
    "    g.fig.subplots_adjust(top=0.85)\n",
    "    g.fig.suptitle(f'{metric.replace(\"_\", \" \").title()} por número de capas, estructura y tolerancia (5-Fold)')\n",
    "    g.set_axis_labels(\"Nº de capas\", metric.replace(\"_\", \" \").title())\n",
    "    g._legend.set_title(\"Estructura de neuronas\")\n",
    "    plt.savefig(f\"/content/{metric}_comparacion_modelos_tolerancia_kfold.png\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"Evaluación con validación cruzada completada, matrices de confusión generadas y resultados exportados.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOI3a/7r0B48/NQFZWPWx5+",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
